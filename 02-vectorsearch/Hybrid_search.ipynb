{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2af472c5-ef9b-4fce-8fa2-59737fbd9dce",
   "metadata": {},
   "source": [
    "### Step 1: Connect to Qdrant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "240e6085-6fb4-445a-9e5d-4076a716a094",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/python/3.12.1/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CollectionsResponse(collections=[CollectionDescription(name='zoomcamp-sparse'), CollectionDescription(name='zoomcamp-rag'), CollectionDescription(name='zoomcamp-sparse-and-dense'), CollectionDescription(name='zoomcamp-faq')])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from qdrant_client import QdrantClient\n",
    "\n",
    "client = QdrantClient(\"http://localhost:6333\")\n",
    "client.get_collections()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5dcdbbd-42a2-433e-a145-77bfa5744750",
   "metadata": {},
   "source": [
    "### Step 2: Sparse vector search with BM25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f89de68f-c81a-4aa9-ae0b-f20b12c1a7f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "docs_url = 'https://github.com/alexeygrigorev/llm-rag-workshop/raw/main/notebooks/documents.json'\n",
    "docs_response = requests.get(docs_url)\n",
    "documents_raw = docs_response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d7fe199-0f86-425f-9a7a-7a6dc667830e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection_name=\"zoomcamp-sparse\"\n",
    "qd_client = QdrantClient(\"http://localhost:6333\") #connecting to local Qdrant instance\n",
    "qd_client.delete_collection(collection_name=collection_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "82dfcd35-28a8-4fe3-a7e7-6621488eb078",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We need to create a collection first. Qdrant will handle the IDF calculations, if we configure it to. \n",
    "# That's required for BM25, otherwise it won't boost the rare words.\n",
    "\n",
    "from qdrant_client import models\n",
    "\n",
    "# Create the collection with specified sparse vector parameters\n",
    "client.create_collection(\n",
    "    collection_name=\"zoomcamp-sparse\",\n",
    "    sparse_vectors_config={\n",
    "        \"bm25\": models.SparseVectorParams(\n",
    "            modifier=models.Modifier.IDF,\n",
    "        )\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "17449ea0-136c-4d40-b839-8f8f45decfe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 18 files: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 18/18 [00:01<00:00, 16.79it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "UpdateResult(operation_id=0, status=<UpdateStatus.COMPLETED: 'completed'>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# FastEmbed comes with a BM25 implementation that we can use as any other model.\n",
    "\n",
    "import uuid\n",
    "\n",
    "# Send the points to the collection\n",
    "client.upsert(\n",
    "    collection_name=\"zoomcamp-sparse\",\n",
    "    points=[\n",
    "        models.PointStruct(\n",
    "            id=uuid.uuid4().hex,\n",
    "            vector={\n",
    "                \"bm25\": models.Document(\n",
    "                    text=doc[\"text\"], \n",
    "                    model=\"Qdrant/bm25\",\n",
    "                ),\n",
    "            },\n",
    "            payload={\n",
    "                \"text\": doc[\"text\"],\n",
    "                \"section\": doc[\"section\"],\n",
    "                \"course\": course[\"course\"],\n",
    "            }\n",
    "        )\n",
    "        for course in documents_raw\n",
    "        for doc in course[\"documents\"]\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ee5c671-b4bb-43a3-b10f-4244fea1389e",
   "metadata": {},
   "source": [
    "### Step 3: Running sparse vector search with BM25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "571f28d1-689d-491f-93b6-55a821ad5389",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Right now, our vectors are ready to be searched over. Let's create a helper function.\n",
    "\n",
    "def search(query: str, limit: int = 1) -> list[models.ScoredPoint]:\n",
    "    results = client.query_points(\n",
    "        collection_name=\"zoomcamp-sparse\",\n",
    "        query=models.Document(\n",
    "            text=query,\n",
    "            model=\"Qdrant/bm25\",\n",
    "        ),\n",
    "        using=\"bm25\",\n",
    "        limit=limit,\n",
    "        with_payload=True,\n",
    "    )\n",
    "\n",
    "    return results.points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "33d444c0-d99a-4191-8c36-da7730469a17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = search(\"Qdrant\")\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd2a3d0a-1184-4a92-bd5b-1337d1900372",
   "metadata": {},
   "source": [
    "Sparse vectors can return no results, if none of the keywords from the query were ever used in the documents. No matter if there are some synonyms. Terminology does matter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4e052057-5183-40b3-b649-b1045ca2c63e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You can use round() function or f-strings\n",
      "round(number, 4)  - this will round number up to 4 decimal places\n",
      "print(f'Average mark for the Homework is {avg:.3f}') - using F string\n",
      "Also there is pandas.Series. round idf you need to round values in the whole Series\n",
      "Please check the documentation\n",
      "https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.round.html#pandas.Series.round\n",
      "Added by Olga Rudakova\n"
     ]
    }
   ],
   "source": [
    "results = search(\"pandas\")\n",
    "print(results[0].payload[\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ddb9dd-5388-41e2-81ee-e58438e56de3",
   "metadata": {},
   "source": [
    "Scores returned by BM25 are not calculated with cosine similarity, but with BM25 formula. They are not bounded to a specific range, but are virtually unbounded. Let's see how they may look like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c82e1dcd-2631-458d-b3ce-7f7db140d1e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.0392046"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[0].score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7565993c-7875-4c9c-a1f2-469c5f6b489d",
   "metadata": {},
   "source": [
    "That's an important observation before we start implementing hybrid search."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdaaf159-fa74-4fa7-9ebe-d30f161e8594",
   "metadata": {},
   "source": [
    "Qdrant's .query_points method allows building multi-step search pipelines which can incorporate various methods into a single call. For example, we can retrieve some candidates with dense vector search, and then rerank them with sparse search, or use a fast method for initial retrieval and precise, but slow, reranking.\n",
    "\n",
    "Let's create another collection that will keep both dense and sparse representations. Qdrant named vectors allow us to store multiple representations per point and it proves useful especially when we want to use mulitple models in our applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e8b500f1-2bd3-48fd-b684-da16adec9a1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection_name2=\"zoomcamp-sparse-and-dense\",\n",
    "\n",
    "qd_client.delete_collection(collection_name=collection_name2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b4dbc08e-e31f-460a-8d16-cbdb45888216",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the collection with both vector types\n",
    "client.create_collection(\n",
    "    collection_name=\"zoomcamp-sparse-and-dense\",\n",
    "    vectors_config={\n",
    "        # Named dense vector for jinaai/jina-embeddings-v2-small-en\n",
    "        \"jina-small\": models.VectorParams(\n",
    "            size=512,\n",
    "            distance=models.Distance.COSINE,\n",
    "        ),\n",
    "    },\n",
    "    sparse_vectors_config={\n",
    "        \"bm25\": models.SparseVectorParams(\n",
    "            modifier=models.Modifier.IDF,\n",
    "        )\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "70694785-95fd-46eb-a9a4-a829765528b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UpdateResult(operation_id=0, status=<UpdateStatus.COMPLETED: 'completed'>)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We have to upload all the vectors into the newly created collection.\n",
    "client.upsert(\n",
    "    collection_name=\"zoomcamp-sparse-and-dense\",\n",
    "    points=[\n",
    "        models.PointStruct(\n",
    "            id=uuid.uuid4().hex,\n",
    "            vector={\n",
    "                \"jina-small\": models.Document(\n",
    "                    text=doc[\"text\"],\n",
    "                    model=\"jinaai/jina-embeddings-v2-small-en\",\n",
    "                ),\n",
    "                \"bm25\": models.Document(\n",
    "                    text=doc[\"text\"], \n",
    "                    model=\"Qdrant/bm25\",\n",
    "                ),\n",
    "            },\n",
    "            payload={\n",
    "                \"text\": doc[\"text\"],\n",
    "                \"section\": doc[\"section\"],\n",
    "                \"course\": course[\"course\"],\n",
    "            }\n",
    "        )\n",
    "        for course in documents_raw\n",
    "        for doc in course[\"documents\"]\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "295359b6-b67e-4e1b-bf9b-2b2962717ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_stage_search(query: str, limit: int = 1) -> list[models.ScoredPoint]:\n",
    "    results = client.query_points(\n",
    "        collection_name=\"zoomcamp-sparse-and-dense\",\n",
    "        prefetch=[\n",
    "            models.Prefetch(\n",
    "                query=models.Document(\n",
    "                    text=query,\n",
    "                    model=\"jinaai/jina-embeddings-v2-small-en\",\n",
    "                ),\n",
    "                using=\"jina-small\",\n",
    "                # Prefetch ten times more results, then\n",
    "                # expected to return, so we can really rerank\n",
    "                limit=(10 * limit),\n",
    "            ),\n",
    "        ],\n",
    "        query=models.Document(\n",
    "            text=query,\n",
    "            model=\"Qdrant/bm25\", \n",
    "        ),\n",
    "        using=\"bm25\",\n",
    "        limit=limit,\n",
    "        with_payload=True,\n",
    "    )\n",
    "\n",
    "    return results.points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3ddb8984-d41d-402c-93c0-b5549906216f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"text\": \"Even though the upload works using aws cli and boto3 in Jupyter notebook.\\nSolution set the AWS_PROFILE environment variable (the default profile is called default)\",\n",
      "  \"section\": \"Module 4: Deployment\",\n",
      "  \"question\": \"Uploading to s3 fails with An error occurred (InvalidAccessKeyId) when calling the PutObject operation: The AWS Access Key Id you provided does not exist in our records.\\\"\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import json\n",
    "\n",
    "random.seed(202506)\n",
    "\n",
    "course = random.choice(documents_raw)\n",
    "course_piece = random.choice(course[\"documents\"])\n",
    "print(json.dumps(course_piece, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e967817c-0515-46a4-bd1c-66510ea6b19f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem description. How can we connect s3 bucket to MLFLOW?\n",
      "Solution: Use boto3 and AWS CLI to store access keys. The access keys are what will be used by boto3 (AWS' Python API tool) to connect with the AWS servers. If there are no Access Keys how can they make sure that they have the right to access this Bucket? Maybe you're a malicious actor (Hacker for ex). The keys must be present for boto3 to talk to the AWS servers and they will provide access to the Bucket if you possess the right permissions. You can always set the Bucket as public so anyone can access it, now you don't need access keys because AWS won't care.\n",
      "Read more here: https://boto3.amazonaws.com/v1/documentation/api/latest/guide/credentials.html\n",
      "Added by Akshit Miglani\n"
     ]
    }
   ],
   "source": [
    "results = multi_stage_search(course_piece[\"question\"])\n",
    "print(results[0].payload[\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2dab9ac-0947-4ad8-921e-ae661acb1cd7",
   "metadata": {},
   "source": [
    "### Hybrid search\n",
    "Hybrid Search is a technique for combining results coming from different search methods - for example dense and sparse. Hybrid Search is a technique for combining results coming from different search methods - for example dense and sparse. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70a274e7-f9c9-429c-997b-ce6f5ded32ad",
   "metadata": {},
   "source": [
    "#### Fusion\n",
    "Fusion is a set of methods which work on the scores/ranking as returned by the individual methods. \n",
    "There are various ways of how to achieve that, but Reciprocal Rank Fusion is the most popular technique. It is based on the rankings of the documents in each methods used, and these rankings are used to calculate the final scores. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1677e1f2-20e0-4ebc-a136-46dc5df5cebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rrf_search(query: str, limit: int = 1) -> list[models.ScoredPoint]:\n",
    "    results = client.query_points(\n",
    "        collection_name=\"zoomcamp-sparse-and-dense\",\n",
    "        prefetch=[\n",
    "            models.Prefetch(\n",
    "                query=models.Document(\n",
    "                    text=query,\n",
    "                    model=\"jinaai/jina-embeddings-v2-small-en\",\n",
    "                ),\n",
    "                using=\"jina-small\",\n",
    "                limit=(5 * limit),\n",
    "            ),\n",
    "            models.Prefetch(\n",
    "                query=models.Document(\n",
    "                    text=query,\n",
    "                    model=\"Qdrant/bm25\",\n",
    "                ),\n",
    "                using=\"bm25\",\n",
    "                limit=(5 * limit),\n",
    "            ),\n",
    "        ],\n",
    "        # Fusion query enables fusion on the prefetched results\n",
    "        query=models.FusionQuery(fusion=models.Fusion.RRF),\n",
    "        with_payload=True,\n",
    "    )\n",
    "\n",
    "    return results.points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "50f2813d-f351-430c-b9ee-7dba41c1ccde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"text\": \"Even though the upload works using aws cli and boto3 in Jupyter notebook.\\nSolution set the AWS_PROFILE environment variable (the default profile is called default)\",\n",
      "  \"section\": \"Module 4: Deployment\",\n",
      "  \"question\": \"Uploading to s3 fails with An error occurred (InvalidAccessKeyId) when calling the PutObject operation: The AWS Access Key Id you provided does not exist in our records.\\\"\"\n",
      "}\n",
      "Problem description. How can we connect s3 bucket to MLFLOW?\n",
      "Solution: Use boto3 and AWS CLI to store access keys. The access keys are what will be used by boto3 (AWS' Python API tool) to connect with the AWS servers. If there are no Access Keys how can they make sure that they have the right to access this Bucket? Maybe you're a malicious actor (Hacker for ex). The keys must be present for boto3 to talk to the AWS servers and they will provide access to the Bucket if you possess the right permissions. You can always set the Bucket as public so anyone can access it, now you don't need access keys because AWS won't care.\n",
      "Read more here: https://boto3.amazonaws.com/v1/documentation/api/latest/guide/credentials.html\n",
      "Added by Akshit Miglani\n"
     ]
    }
   ],
   "source": [
    "results = rrf_search(course_piece[\"question\"])\n",
    "print(json.dumps(course_piece, indent=2))\n",
    "print(results[0].payload[\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6bc4f79-c955-40ad-aaf2-93a09d1a9757",
   "metadata": {},
   "source": [
    "#### Reranking\n",
    "Reranking is a broader term related to Hybrid Search. Fusion is one of the ways to rerank the results of multiple methods, but you can also apply a slower method that won't be effective enough to search over all the documents. But there is more to it. Business rules are often important for retrieval, as you prefer to show documents coming from the most recent news, for instance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3af39ab-808a-43b2-83d7-66a35a45cd1c",
   "metadata": {},
   "source": [
    "### Next steps\n",
    "Dense and sparse vector search methods might not be enough in some cases, but both are fast enough to be used as initial retrievers. Plenty of more accurate yet slower methods exist, such as cross-encoders or multivector representations. These topics are definitely more advanced, and we won't cover them right now. However, it's good to mention them so you are aware they exist."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2529782f-e556-46a8-be70-87b97cb9a5fc",
   "metadata": {},
   "source": [
    "https://qdrant.tech/documentation/advanced-tutorials/using-multivector-representations/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5906a23-e3f7-47f8-b19f-a86481727e1c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
