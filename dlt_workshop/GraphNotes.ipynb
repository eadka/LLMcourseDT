{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e2298ad-86d4-4e40-b790-6181130480a5",
   "metadata": {},
   "source": [
    "## Notes on Graph RAGs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8febccca-ed7b-4f23-aa11-2da7a219f1d3",
   "metadata": {},
   "source": [
    "#### What is Graph RAG?\n",
    "A Graph RAG augments the standard Retrieval-Augmented Generation (RAG) framework by introducing a knowledge graph into the retrieval step. This graph provides semantic, logical, or structural relationships between documents or conceptsâ€”something a vanilla vector search might miss."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ff76bbe6-b386-4ef8-a1b5-d5a5f196ccce",
   "metadata": {},
   "source": [
    "#### Core Architecture Pattern\n",
    "\n",
    "1. Initial Dense Retrieval (Vector Search)\n",
    "     - We perform a semantic vector search using the query to retrieve a small, high-relevance core set of documents (D_core)\n",
    "     - THese documents are typically nodes in a graph, either representing the documents themselves or entities within the documents\n",
    "     - This stage ensures precision in matching query intent with text\n",
    "  \n",
    "2. Graph traversal for context expansion\n",
    "     - Use the knowledge graph to expand the context by exploring neighbouring nodes of D_core\n",
    "\n",
    "3. Contextual re-ranking and filtering\n",
    "     - Post traversal we may have hundreds or thousands of documents\n",
    "     - Use ranking mechanisms like PageRank, Betweenness or Cross-encoders (BERT)\n",
    "\n",
    "4. Context packing and prompt construction\n",
    "     - Curate the final subset (say, top 10-30 documents) for inclusion in LLM prompt\n",
    "\n",
    "6. LLM Generation\n",
    "     - The LLM (e.g GPT, Claude, etc.) takes the curated, context-rich documents and generates answers\n",
    "     - The increased context density (via graph expansion) improves factual grounding and reasoning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac392e40-c1b2-465a-af38-ae8b988a7a7c",
   "metadata": {},
   "source": [
    "#### Benefits of Graph RAG in combination with a vector search\n",
    "1. Accuracy - improved accuracy - almost 3x\n",
    "2. Easier development - if a knowledge graph is already created\n",
    "3. Explainability and governance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23c4338b-3642-4467-9a43-0e825d6c721e",
   "metadata": {},
   "source": [
    "## dlt\n",
    "dlt is an open-source Python library that loads data from various, often messy data sources into well-structured, live datasets.\n",
    "\n",
    "In the workshop, dlt is used in the first demo to read a dataset into a local DuckDB destination and in the second demo from an REST API source to a local file system \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40c73905-a16c-4111-896d-1c9f5432678c",
   "metadata": {},
   "source": [
    "### Cognee\n",
    "Cognee is a tool to turn data into a queryable memory knowledge graphs. \n",
    "\n",
    "It allows:\n",
    "- Adding structured or unstructured data\n",
    "- Automatically build a knowledge graph from it\n",
    "- Ask natural language questions and get grounded, context rich results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af1d3773-3f22-4a1e-8429-4326b40ece68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a00d827-a482-4fc8-828a-82e371a0b2ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
