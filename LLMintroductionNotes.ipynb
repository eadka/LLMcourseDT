{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "08938497-580f-4ab4-8517-061c8087b9f0",
   "metadata": {},
   "source": [
    "# Notes on Introduction to LLMs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03b44f25-d512-4071-834b-95ee3caf39fb",
   "metadata": {},
   "source": [
    "### Course framework"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c0a289-43ae-4e02-b488-bc8e9c8ac544",
   "metadata": {},
   "source": [
    "LLMs is the abbrevation for Large Language Models and they have the framework pictured below"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "491cdecc-bf13-4ca8-a29f-548227d6eff1",
   "metadata": {},
   "source": [
    "![LLMs:Large language models](LLMs.png \"LLM\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "298918b0-f721-4b00-bcf5-880bb2c6e93e",
   "metadata": {},
   "source": [
    "Language models are models that predict the next word/token based on the words before. The difference between small and large language models is that small language models have fewer parameters while large have billions and parameters and are also trained on tons of data while small ones are not. The interation with a LLM seems seamless like we are having a conversation.\n",
    "\n",
    "LLMs use neural networks under the hood but this is out of the scope of this course and we are going to treat LLMs like black boxes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "220c29f2-39c7-4926-bb0e-a9e4a81cd9fb",
   "metadata": {},
   "source": [
    "### RAG: Retrieval Augmented Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb85ceb9-6ea4-476c-9125-b7648a5f03cc",
   "metadata": {},
   "source": [
    "Generation of answers come from LLMs and this generation need to be augmented/ helped by a Retrieval system like a search engine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ad7354a-bebb-46f9-b039-4013ded7ed2d",
   "metadata": {},
   "source": [
    "![RAG:Retrieval Augmented Generation](RAG.png \"RAG\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9baa9f58-cb5a-4fc1-9248-2b098cd15778",
   "metadata": {},
   "source": [
    "The question is sent by the user to the knowledge/data base which has the relevant information (D1,...D5).\n",
    "A prompt is created and the documents D1,..D5 are used as the context in the prompt\n",
    "The prompt is sent to the LLM and using this along with the context, the LLM can then generate the relevant answers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "565e3fb5-1ff0-46a4-b5a3-2e69880a62c1",
   "metadata": {},
   "source": [
    "The DB and the LLMs in the above diagram can be replaced as needed. Over the course, the DB is firstly replaced by a toy search engine and then elastic search. Later we would also use vector based search as the DB. \n",
    "\n",
    "Similarly with the LLM we first use ChatGPT and later go on to try other ones like Llama"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "552a6cfb-386c-4845-8aad-e2d8d10f1ccc",
   "metadata": {},
   "source": [
    "### Preparing the environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af7f93ac-c581-4043-b1cb-549723901b01",
   "metadata": {},
   "source": [
    "#### Codespaces\n",
    "1. Create a github account if not already available\n",
    "2. Create a public repository\n",
    "3. Gitignore should be python\n",
    "4. License (not relevant)\n",
    "\n",
    "Steps to open Codespaces in VS code in the desktop:\n",
    "- Create a repository in github\n",
    "- Click on <> Code and choose the Codespaces tab and click on **Create codespace on main**\n",
    "- This will start visual studio in a browser. We dont want to use the browser so install Visual Studio in the system.\n",
    "- To open the environment in the desktop, search for **Open in VS COde Desktop.** \n",
    "- Install the extensions for code spaces when VS code starts codespaces for the first time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de8d530-2bb3-41b9-a1d6-1e8b8ab3a4c1",
   "metadata": {},
   "source": [
    "![Codespaces](CodespacesLLMZoomcamp.png \"Codespaces\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7ee1706-926d-477c-89cb-eb5cb2249c0b",
   "metadata": {},
   "source": [
    "##### Install the libraries and codespaces\n",
    "pip install tqdm notebook==7.1.2 openai elasticsearch==8.13.0 pandas scikit-learn ipywidgets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b513371e-b4d0-47fb-8d30-5c66877e3db1",
   "metadata": {},
   "source": [
    "#### Open AI KeyGo to platform.openai.com and open an account\n",
    "- Go to API key and create a new API key. Keep this key safe and not expose it.\n",
    "- Take this key and open the key in the environment with the following: export OPENAI_API_KEY='PUTTHEKEYVALUEHERE'\n",
    "- Start Jupyter notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "857df64f-ed6e-439e-85b7-5b7d5f24a750",
   "metadata": {},
   "source": [
    "** For the rest of the course on introduction and creating a RAG with the sample search engine and then with the elastic search and ChatGPT, use the **rag-intro.ipynb**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d7376f-3737-4e52-9e08-7b616c8427c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
